## 训练新的强化学习算法的技巧
### 1 使用低维状态空间的环境来训练
* 建议使用Pendulum来训练，因为这是一个二维状态问题，角度和速度
* 二维状态可以可视化一些值函数来帮助调试
### 2 测试算法的合理性，对于特定算法构造对应问题
* 当环境状态空间比较小的时候，不要overfit你的训练
### 3 使用你熟悉的环境来测试
* 可以知道在这个环境里面需要训练多久
* 可以知道reward大概怎么变化
## 调试新任务的技巧
### 从最简单的开始，直到你看到它学到东西
* 例如简化你的特征空间
    * 比如面对一个图像输入的强化学习问题，可能比较难构造比较好的特征，使用cnn比较难学，所以可以通过对task的理解，直接编码位置
    x，y，然后学习
    * 直到在简化的问题中有效的学习之后，然后再切换到难的问题
* 例如简化reward函数
    * 设计reward能够快速让agent学到正确的事情，这样可以快速知道算法是不是对的
    * 例如给agent比较密集的reward会比给它很离散的reward要好得多
## 强化学习的框架技巧
### 1 观察随机策略的的表现
* 观察随机策略对你有没有启发
### 2 确定输入观测是正确的
* 人为的通过输入判断能不能给出输出，如果自己做不到，RL可能也做不到
### 3 确定尺度是正确的
* observation 均值为0，方差为1
* reward 缩放到相应的尺度
## 重现算法
### 比需要的数据，提供更多的采样
* 让agent学的更久
* 微调超参数
* 考虑更大的batch_size
* batch_size比较小，那么噪声会比较大
## 通用的训练技巧
### 1 标准化数据
* observation 计算平均值和标准差然后变换
* reward 缩放不要移动
### 2 衰减率调节
* 确定的给与了多少信度分配
* 例如0.99相当于更加相信近期的利益